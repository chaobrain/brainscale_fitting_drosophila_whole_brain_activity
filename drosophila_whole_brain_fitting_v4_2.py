# Copyright 2025 BDP Ecosystem Limited. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

"""

1、连续数值的 firing rate tokenization

使用 uniform binning，将连续数值的 firing rate tokenize为 若干个 bin，每个 bin 代表 0.1 mV 的 firing rate。
每个 bin 对应一个 token，token 之间的距离为 0.1 mV。每个bin使用随机的 embedding 表示。

2、训练范式

使用上一个时刻的 firing rate 作为输入，当前时刻的 firing rate 作为输出。

"""

from __future__ import annotations

import datetime
import os
import platform
import sys
import time
from pathlib import Path
from typing import Callable

from tqdm import tqdm

if (
    platform.system() == 'Linux'
    and
    platform.platform() not in ['Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35']
):
    import matplotlib

    matplotlib.use('Agg')

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.99'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['JAX_TRACEBACK_FILTERING'] = 'off'
sys.path.append('/mnt/d/codes/projects/brainscale')
sys.path.append('/mnt/d/codes/projects/brainevent')
sys.path.append('D:/codes/projects/brainscale')
sys.path.append('D:/codes/projects/brainevent')

import brainevent
import brainstate
import braintools
import brainscale
import brainunit as u
import jax
import jax.numpy as jnp

from utils import g_init, v_init, count_pre_post_connections, barplot, output


class Population(brainstate.nn.Neuron):
    """
    A population of neurons with leaky integrate-and-fire dynamics.

    This class implements a population of leaky integrate-and-fire neurons for the Drosophila brain
    simulation, with connectivity based on the FlyWire connectome dataset. Each neuron follows
    standard LIF dynamics with customizable parameters for membrane properties, synaptic
    transmission, and spike generation.

    The dynamics of the neurons are given by the following equations::

       dv/dt = (v_0 - v + g) / t_mbr : volt (unless refractory)
       dg/dt = -g / tau               : volt (unless refractory)

    Parameters
    ----------
    flywire_version : str or int, optional
        Version of the FlyWire connectome dataset to use ('630' or '783'), defaults to '783'
    v_rest : u.Quantity, optional
        The resting potential of the neurons, defaults to 0 mV
    v_reset : u.Quantity, optional
        The reset potential of the neurons after a spike, defaults to 0 mV
    v_th : u.Quantity, optional
        The threshold potential of the neurons for spiking, defaults to 1 mV
    tau_m : u.Quantity, optional
        The membrane time constant of the neurons, defaults to 20 ms
    tau_syn : u.Quantity, optional
        The synaptic time constant of the neurons, defaults to 5 ms
    tau_ref : u.Quantity or None, optional
        The refractory period of the neurons, defaults to 2.2 ms
    spk_fun : Callable, optional
        The spike function of the neurons, defaults to ReluGrad with width=1.5
    V_init : Callable, optional
        Initialization function for membrane voltage, defaults to Constant(0 mV)
    g_init : Callable, optional
        Initialization function for synaptic conductance, defaults to Constant(0 mV)
    name : str, optional
        The name of the population

    Attributes
    ----------
    n_neuron : int
        Number of neurons in the population
    flyid2i : dict
        Mapping from FlyWire IDs to neuron indices
    i2flyid : dict
        Mapping from neuron indices to FlyWire IDs
    v : brainscale.ETraceState
        Membrane potential state variable
    g : brainscale.ETraceState
        Synaptic conductance state variable
    spike_count : brainscale.ETraceState
        Counter for spikes generated by each neuron
    t_ref : brainstate.HiddenState, optional
        Timestamp of last spike for refractory period calculation
    """

    def __init__(
        self,
        flywire_version: str | int = '783',
        v_rest: u.Quantity = 0 * u.mV,  # resting potential
        v_reset: u.Quantity = 0 * u.mV,  # reset potential after spike
        v_th: u.Quantity = 1 * u.mV,  # potential threshold for spiking
        tau_m: u.Quantity = 20 * u.ms,  # membrane time constant
        # Jürgensen et al https://doi.org/10.1088/2634-4386/ac3ba6
        tau_syn: u.Quantity = 5 * u.ms,  # synaptic time constant
        # Lazar et al https://doi.org/10.7554/eLife.62362
        tau_ref: u.Quantity | None = 2.2 * u.ms,  # refractory period
        spk_fun: Callable = brainstate.surrogate.ReluGrad(width=1.5),  # spike function
        V_init: Callable = brainstate.init.Constant(0 * u.mV),  # initial voltage
        g_init: Callable = brainstate.init.Constant(0. * u.mV),  # initial voltage
        name: str = None,
    ):
        # connectome data
        if flywire_version in ['783', 783]:
            path_neu = 'data/Completeness_783.csv'
            path_syn = 'data/Connectivity_783.parquet'
        elif flywire_version in ['630', 630]:
            path_neu = 'data/Completeness_630_final.csv'
            path_syn = 'data/Connectivity_630_final.parquet'
        else:
            raise ValueError('flywire_version must be either "783" or "630"')
        self.flywire_version = flywire_version

        self.path_neu = Path(path_neu)
        self.path_syn = Path(path_syn)

        print('Loading neuron information ...')

        # neuron ids
        flywire_ids = pd.read_csv(self.path_neu, index_col=0)
        self.n_neuron = len(flywire_ids)

        super().__init__(self.n_neuron, name=name)

        self.flyid2i = {f: i for i, f in enumerate(flywire_ids.index)}
        self.i2flyid = {i: f for i, f in enumerate(flywire_ids.index)}

        # parameters
        self.v_rest = v_rest
        self.v_reset = v_reset
        self.v_th = v_th
        self.tau_m = tau_m
        self.tau_syn = tau_syn
        self.tau_ref = tau_ref if tau_ref is None else u.math.full(self.varshape, tau_ref)
        self.spk_fun = spk_fun

        # initializer
        self.V_init = V_init
        self.g_init = g_init

    def init_state(self):
        self.v = brainscale.ETraceState(brainstate.init.param(self.V_init, self.varshape))
        self.g = brainscale.ETraceState(brainstate.init.param(self.g_init, self.varshape))
        self.spike_count = brainscale.ETraceState(jnp.zeros(self.varshape, dtype=brainstate.environ.dftype()))
        if self.tau_ref is not None:
            self.t_ref = brainstate.HiddenState(
                brainstate.init.param(brainstate.init.Constant(-1e7 * u.ms), self.varshape)
            )

    def reset_state(self):
        self.reset_spk_count()
        self.v.value = brainstate.init.param(self.V_init, self.varshape)
        if self.tau_ref is not None:
            self.t_ref.value = brainstate.init.param(brainstate.init.Constant(-1e7 * u.ms), self.varshape)

    def reset_spk_count(self, batch_size=None):
        self.spike_count.value = brainstate.init.param(jnp.zeros, self.varshape, batch_size)

    def get_refractory(self):
        if self.tau_ref is None:
            return jnp.zeros(self.varshape, dtype=bool)
        else:
            t = brainstate.environ.get('t')
            ref = (t - self.t_ref.value) <= self.tau_ref
            return ref

    def get_spike(self, v=None):
        v = self.v.value if v is None else v
        return self.spk_fun((v - self.v_th) / (1. * u.mV))

    def update(self, x: u.Quantity[u.mV]):
        t = brainstate.environ.get('t')

        # numerical integration
        dg = lambda g, t: -g / self.tau_syn
        dv = lambda v, t, g: (self.v_rest - v + g) / self.tau_m
        g = brainstate.nn.exp_euler_step(dg, self.g.value, t)
        g += x  # external input current
        v = brainstate.nn.exp_euler_step(dv, self.v.value, t, g)
        v = self.sum_delta_inputs(v)

        # # numerical integration
        # dg = lambda g, t: -g / self.tau_syn
        # dv = lambda v, t, g: (self.v_rest - v + g) / self.tau_m
        # g = brainstate.nn.exp_euler_step(dg, self.g.value, t)
        # v = brainstate.nn.exp_euler_step(dv, self.v.value, t, self.g.value)
        # v = self.sum_delta_inputs(v)
        # g += x  # external input current

        # refractory period
        if self.tau_ref is not None:
            ref = (t - self.t_ref.value) <= self.tau_ref
            v = u.math.where(ref, self.v.value, v)
            g = u.math.where(ref, self.g.value, g)

        # spikes
        spk = self.get_spike(v)
        self.spike_count.value += spk

        # update states
        spk_current = jax.lax.stop_gradient(spk)
        self.v.value = spk_current * (self.v_reset - v) + v
        self.g.value = g - spk_current * g
        if self.tau_ref is not None:
            self.t_ref.value = u.math.where(spk, t, self.t_ref.value)
        return spk


def load_syn(flywire_version: str | int) -> brainevent.CSR:
    """
    Load synaptic connectivity data from the FlyWire connectome dataset.

    This function loads the neuronal connection data for the Drosophila brain from a
    specified FlyWire connectome version and constructs a Compressed Sparse Row (CSR)
    matrix representation of the synaptic connectivity.

    Parameters
    ----------
    flywire_version : str or int
        Version identifier for the FlyWire connectome dataset.
        Accepted values are '630', 630, '783', or 783.

    Returns
    -------
    brainevent.CSR
        A compressed sparse row matrix representing the synaptic connectivity,
        where each entry (i,j) represents the connection weight from neuron i to neuron j.

    Raises
    ------
    ValueError
        If the flywire_version is not one of the supported versions ('630', 630, '783', 783).

    Notes
    -----
    The function processes the connectivity data by:
    1. Loading neuron information to determine the total number of neurons
    2. Loading synaptic connections from the parquet file
    3. Sorting connections by presynaptic neuron indices
    4. Converting the data to CSR format
    """
    if flywire_version in ['783', 783]:
        path_neu = 'data/Completeness_783.csv'
        path_syn = 'data/Connectivity_783.parquet'
    elif flywire_version in ['630', 630]:
        path_neu = 'data/Completeness_630_final.csv'
        path_syn = 'data/Connectivity_630_final.parquet'
    else:
        raise ValueError('flywire_version must be either "783" or "630"')

    # neuron information
    flywire_ids = pd.read_csv(path_neu, index_col=0)
    n_neuron = len(flywire_ids)

    # synapses: CSR connectivity matrix
    flywire_conns = pd.read_parquet(path_syn)
    i_pre = flywire_conns.loc[:, 'Presynaptic_Index'].values
    i_post = flywire_conns.loc[:, 'Postsynaptic_Index'].values
    weight = flywire_conns.loc[:, 'Excitatory x Connectivity'].values
    sort_indices = np.argsort(i_pre)
    i_pre = i_pre[sort_indices]
    i_post = i_post[sort_indices]
    weight = weight[sort_indices]

    values, counts = np.unique(i_pre, return_counts=True)
    indptr = np.zeros(n_neuron + 1, dtype=int)
    indptr[values + 1] = counts
    indptr = np.cumsum(indptr)
    indices = i_post

    csr = brainevent.CSR(
        (weight, indices, indptr),
        shape=(n_neuron, n_neuron)
    )
    return csr


class Interaction(brainstate.nn.Module):
    """
    A module that handles synaptic interactions between neurons in a spiking network.

    This class implements the synaptic connectivity and signal propagation between neurons
    in a population, supporting both sparse connectivity from connectome data and
    trainable low-rank approximation (LoRA) parameters for efficient learning.

    The module manages synaptic delays and implements different connection modes,
    particularly focusing on a combined sparse and low-rank connectivity approach
    for computational efficiency while maintaining biological plausibility.

    Parameters
    ----------
    pop : Population
        The neural population containing the neurons that will interact.
    scale_factor : u.Quantity
        Scaling factor for the synaptic weights, specified with units.
    conn_mode : str, optional
        Connection mode specifying how neurons are connected, defaults to 'sparse+low+rank'.
        Currently only supports 'sparse+low+rank'.
    conn_param_type : type, optional
        Parameter type for connection weights (typically a brainscale parameter class),
        defaults to brainscale.ETraceParam.
    n_rank : int, optional
        Rank for low-rank approximation in LoRA, defaults to 20.

    Attributes
    ----------
    pop : Population
        The neural population being modeled.
    delay : brainstate.nn.Delay
        Module handling synaptic transmission delays.
    conn : brainstate.nn.SparseLinear
        Sparse connectivity matrix representing the connectome.
    lora : brainscale.nn.LoRA
        Low-rank approximation module for trainable connectivity.
    conn_mode : str
        The connection mode being used.
    scale_factor : u.Quantity
        Scaling factor applied to synaptic weights.
    """

    def __init__(
        self,
        pop: Population,
        scale_factor: u.Quantity,
        conn_mode: str = 'sparse+low+rank',
        conn_param_type: type = brainscale.ETraceParam,
        n_rank: int = 20,
    ):
        super().__init__()

        # neuronal and synaptic dynamics
        self.pop = pop

        # delay for changes in post-synaptic neuron
        # Paul et al 2015 doi: https://doi.org/10.3389/fncel.2015.00029
        self.delay = brainstate.nn.Delay(
            jax.ShapeDtypeStruct(self.pop.varshape, brainstate.environ.dftype()),
            entries={'D': 1.8 * u.ms}
        )

        print('Loading synapse information ...')
        csr = load_syn(self.pop.flywire_version)

        # connectivity matrix
        self.conn_mode = conn_mode
        self.scale_factor = scale_factor

        if conn_mode == 'sparse+low+rank':
            # do not train sparse connection
            self.conn = brainstate.nn.SparseLinear(csr, b_init=None, param_type=brainstate.FakeState)

            # train LoRA weights
            self.lora = brainscale.nn.LoRA(
                in_features=self.pop.in_size,
                lora_rank=n_rank,
                out_features=self.pop.out_size,
                A_init=brainstate.init.LecunNormal(unit=u.mV),
                param_type=conn_param_type
            )

        else:
            raise ValueError('conn_mode must be either "sparse" or "sparse+low+rank"')

    def update(self, x=None):
        """
        Update the network state based on the current input.

        Args:
            x (Optional): External input to the network. Defaults to None.

        Returns:
            dict: A dictionary containing the spike, voltage, and conductance states.
        """
        # Update the input module for the neuron population delayed spikes
        pre_spk = self.delay.at('D')
        pre_spk = jax.lax.stop_gradient(pre_spk)

        # compute recurrent connections and update neurons
        if self.conn_mode == 'sparse+low+rank':
            inp = self.conn(brainevent.EventArray(pre_spk)) * self.scale_factor
            inp = inp + self.lora(pre_spk)
        else:
            raise ValueError('mode must be either "sparse" or "sparse+low+rank')

        if x is None:
            x = inp
        else:
            x += inp
        spk = self.pop(x)

        # update delay spikes
        self.delay.update(jax.lax.stop_gradient(spk))

        return spk


def get_bins(spike_rates, bin_size, neural_activity_max_fr):
    """
    Create bins for discretizing firing rates in the neural activity data.

    This function generates bin edges for categorizing continuous firing rates into discrete bins.
    The bins start from 0 Hz and increase by the specified bin size until reaching the maximum
    observed firing rate, with a final bin extending to the maximum possible firing rate.

    Parameters
    ----------
    spike_rates : u.Quantity
        Array of spike rates with units (typically Hz) to be binned.
        Used to determine the maximum observed firing rate.
    bin_size : u.Quantity
        Size of each bin in Hz units (e.g., 0.1 Hz).
    neural_activity_max_fr : u.Quantity
        Maximum possible firing rate in Hz units. This value is added as the upper edge
        of the final bin to ensure all firing rates can be properly categorized.

    Returns
    -------
    jnp.ndarray
        An array of bin edges starting from 0 and increasing by bin_size until reaching
        the maximum firing rate, with the final value being neural_activity_max_fr.

    Notes
    -----
    The function ensures all firing rates can be binned by:
    1. Finding the maximum value in the provided spike_rates
    2. Creating regular bins from 0 to this maximum value
    3. Adding an extra bin edge at neural_activity_max_fr to capture any potential outliers
    """
    max_firing_rate = spike_rates.max()
    max_firing_rate = np.ceil(max_firing_rate.to_decimal(u.Hz))
    bins = np.arange(0, max_firing_rate, bin_size.to_decimal(u.Hz))
    bins = np.append(bins, neural_activity_max_fr.to_decimal(u.Hz))
    return jnp.asarray(bins)


def neuropil_to_bin_indices(neuropil_fr: u.Quantity[u.Hz], bins):
    """
    Convert neuropil firing rates to bin indices.

    This method maps the given neuropil firing rates to the corresponding bin indices
    based on the pre-defined bins stored in the class instance.

    Args:
        neuropil_fr (u.Quantity[u.Hz]): Firing rates for each neuropil, specified in Hertz units.

    Returns:
        jnp.ndarray: An array of bin indices corresponding to each input firing rate.
    """
    assert bins.ndim == 1, 'bins must be a 1D array'
    bins = bins.to_decimal(u.Hz) if isinstance(bins, u.Quantity) else bins
    neuropil_fr = neuropil_fr.to_decimal(u.Hz) if isinstance(neuropil_fr, u.Quantity) else neuropil_fr

    # Convert the neuropil firing rates to decimal values in Hertz and digitize them
    # based on the pre-defined bins stored in the class instance.
    fn = lambda x: jnp.digitize(x, bins, False)
    for _ in range(neuropil_fr.ndim - 1):
        fn = jax.vmap(fn)
    bin_indices = fn(neuropil_fr)
    return bin_indices


class NeuralActivity(brainstate.nn.Module):
    """
    A module for managing neural activity data and conversion between neuron firing rates and neuropil activity.

    This class handles the loading, processing, and conversion of neural activity data between different
    representations, particularly focusing on mapping between individual neuron firing rates and
    neuropil-level activity in the Drosophila brain. It manages binning of continuous firing rates
    for discretization and provides methods for simulating neural activity inputs.

    Parameters
    ----------
    pop : Population
        The neural population containing the neurons to be modeled.
    flywire_version : str
        Version of the FlyWire connectome to use (e.g., '630' or '783').
    neural_activity_id : str, optional
        Identifier for the neural activity dataset, defaults to '2017-10-26_1'.
    neural_activity_max_fr : u.Quantity, optional
        Maximum firing rate for neural activity normalization, defaults to 120 Hz.
    param_type : type, optional
        Parameter type for network weights, defaults to brainscale.ETraceParam.
    seed : int, optional
        Random seed for reproducibility, defaults to 2025.
    bin_size : u.Quantity, optional
        Size of bins for discretizing firing rates, defaults to 0.1 Hz.
    noise_sigma : float, optional
        Standard deviation of noise added during input generation, defaults to 0.1.

    Attributes
    ----------
    pop : Population
        The neural population being modeled.
    neuropils : list
        Names of neuropils in the dataset.
    spike_rates : u.Quantity
        Time series of firing rates for each neuropil.
    bins : jnp.ndarray
        Bin edges for discretizing firing rates.
    neuropil_to_connectivity : brainstate.util.NestedDict
        Mapping between neuropils and their connectivity information.
    neuropil2neuron : brainstate.nn.Sequential
        Network mapping from neuropil activity to individual neuron activity.
    """

    def __init__(
        self,
        pop: Population,
        flywire_version: str,
        neural_activity_id: str = '2017-10-26_1',
        neural_activity_max_fr: u.Quantity = 120 * u.Hz,
        param_type: type = brainscale.ETraceParam,
        seed: int = 2025,
        bin_size: u.Quantity = 0.1 * u.Hz,
        noise_sigma: float = 0.1,
    ):
        super().__init__()
        self.pop = pop
        self.noise_sigma = noise_sigma

        # uniform binning
        self.rng = np.random.RandomState(seed)
        self.bin_size = bin_size
        print('Loading neural activity information ...')

        # neural activity data
        self.neural_activity_id = neural_activity_id
        data = np.load(f'./data/spike_rates/ito_{neural_activity_id}_spike_rate.npz')
        self.neuropils = data['areas'][1:]
        self.spike_rates = u.math.asarray(data['rates'][1:] * neural_activity_max_fr).T  # [time, neuropil]
        self.bins = get_bins(self.spike_rates, bin_size, neural_activity_max_fr)

        # connectivity data, which show a given neuropil contains which connections
        print('Loading connectivity information ...')
        if flywire_version in ['783', 783]:
            conn_path = 'data/783_connections_processed.csv'
        elif flywire_version in ['630', 630]:
            conn_path = 'data/630_connections_processed.csv'
        else:
            raise ValueError('flywire_version must be either "783" or "630"')
        connectivity = pd.read_csv(conn_path)
        neuropil_to_connectivity = brainstate.util.NestedDict()
        for i, neuropil in enumerate(self.neuropils):
            # find out all connections (spike source) to a given neuropil
            position = connectivity['neuropil'] == neuropil
            pre_indices = connectivity['pre_index'][position].values
            post_indices = connectivity['post_index'][position].values
            syn_count = connectivity['syn_count'][position].values
            # pre/post-synaptic indices and counts
            (
                pre_indices,
                pre_counts,
                post_indices,
                post_counts,
            ) = count_pre_post_connections(pre_indices, post_indices, syn_count)
            pre_weights = pre_counts / pre_counts.sum()
            post_weights = post_counts / post_counts.sum()
            neuropil_to_connectivity[neuropil] = brainstate.util.NestedDict(
                pre_indices=pre_indices,
                post_indices=post_indices,
                pre_weights=pre_weights,
                post_weights=post_weights,
            )
        self.neuropil_to_connectivity = neuropil_to_connectivity

        # neural activity conversion
        self.neuropil2neuron = brainstate.nn.Sequential(
            brainscale.nn.Linear(
                self.n_neuropil,
                self.pop.varshape,
                w_init=brainstate.init.KaimingNormal(unit=u.mV),
                b_init=brainstate.init.ZeroInit(unit=u.mV),
                param_type=param_type
            ),
            brainscale.nn.ReLU()
        )

    def update(self, embedding):
        noise_weight = self.neuropil2neuron(u.get_mantissa(embedding))

        # excite neurons
        refractory = self.pop.get_refractory()

        # excitation
        brainstate.nn.poisson_input(
            freq=20 * u.Hz,
            num_input=1,
            weight=noise_weight,
            target=self.pop.v,
            refractory=refractory,
        )

    def update_test(self, noise_weight):
        # excite neurons
        refractory = self.pop.get_refractory()

        # excitation
        brainstate.nn.poisson_input(
            freq=20 * u.Hz,
            num_input=1,
            weight=noise_weight,
            target=self.pop.v,
            refractory=refractory,
        )

    @property
    def n_neuropil(self) -> int:
        return self.spike_rates.shape[1]

    @property
    def n_time(self) -> int:
        return self.spike_rates.shape[0]

    @brainstate.compile.jit(static_argnums=0)
    def neuropil_fr_to_embedding(self, neuropil_fr: u.Quantity[u.Hz]):
        """
        Convert firing rates from neuropil-level to embedding-level.
        This method maps firing rates from individual neuropils to the embedding level
        by applying a one-hot encoding to the firing rates.
        
        Args:
            neuropil_fr (u.Quantity[u.Hz]): Firing rates for each neuropil, specified in Hertz units.
            
        Returns:
            u.Quantity[u.Hz]: Embedding-level firing rates, specified in Hertz units.
        """

        def convert(key, fr):
            # convert firing rates to bins
            right_bin_indices = neuropil_to_bin_indices(fr, self.bins)
            left_bin_indices = right_bin_indices - 1
            left = self.bins[left_bin_indices] / u.Hz
            right = self.bins[right_bin_indices] / u.Hz
            return jax.random.uniform(key, left.shape, minval=left, maxval=right)

        if neuropil_fr.ndim == 1:
            return convert(brainstate.random.split_key(), neuropil_fr)
        elif neuropil_fr.ndim == 2:
            return jax.vmap(convert)(brainstate.random.split_key(neuropil_fr.shape[0]), neuropil_fr)
        else:
            raise ValueError

    def neuron_to_neuropil_fr(self, neuron_fr: u.Quantity[u.Hz]):
        """
        Convert firing rates from neuron-level to neuropil-level.

        This method maps firing rates from individual neurons to the neuropil level by
        aggregating the neuron firing rates using weighted sums based on their
        pre-synaptic connections to each neuropil.

        Args:
            neuron_fr (u.Quantity[u.Hz]): Firing rates for each neuron in the population,
                specified in Hertz units.

        Returns:
            u.Quantity[u.Hz]: Firing rates for each neuropil, specified in Hertz units.

        Note:
            The conversion applies the weights defined by the selected conversion method
            ('unique', 'weighted', or 'average') during class initialization.
        """
        neuropil_fr = []
        for i, neuropil in enumerate(self.neuropils):
            # find out all connections (spike source) to a given neuropil
            pre_indices = self.neuropil_to_connectivity[neuropil]['pre_indices']
            pre_weights = self.neuropil_to_connectivity[neuropil]['pre_weights']
            neuropil_fr.append(u.math.sum(neuron_fr[pre_indices] * pre_weights))
        return u.math.asarray(neuropil_fr)

    def read_neuropil_fr(self, i):
        """
        Read the spike rate of a specific neuropil at a given index.

        Args:
            i (int): The index of the spike rate to read from the stored spike rates.

        Returns:
            u.Quantity: The spike rate at the specified index.
        """
        return self.spike_rates[i]

    def iter_data(
        self,
        batch_size: int,
        drop_last: bool = False,
        test_phase: bool = True,
    ):
        """
        Iterate over the neural activity data in batches.

        Args:
            batch_size (int): The size of each batch.
            drop_last (bool, optional): Whether to drop the last batch if it is smaller

        Yields:
            Tuple: A tuple containing the spike rates and neuropils for each batch.
        """
        spike_rates = u.get_mantissa(self.spike_rates)
        if not test_phase:
            spike_rates = np.random.normal(spike_rates, spike_rates * self.noise_sigma)
            spike_rates = np.minimum(spike_rates, 0.)

        for i in range(1, self.n_time, batch_size):
            if i + batch_size > self.n_time:
                if drop_last:
                    break
                batch_size = self.n_time - i

            input_neuropil_fr = spike_rates[i - 1:i + batch_size - 1]
            output_neuropil_fr = spike_rates[i:i + batch_size] * u.Hz
            if test_phase:
                input_embed = input_neuropil_fr
            else:
                input_embed = self.neuropil_fr_to_embedding(input_neuropil_fr)
            yield (
                input_embed,
                output_neuropil_fr,
            )


class DrosophilaSpikingNetwork(brainstate.nn.Module):
    """
    A spiking neural network model for simulating firing rate patterns in the Drosophila brain.

    This class implements a biologically plausible spiking neural network that models
    neuronal activity in the Drosophila brain based on FlyWire connectome data.
    It integrates neural population dynamics, synaptic interactions, and mechanisms
    to process neural activity data for realistic brain simulation.

    Parameters
    ----------
    flywire_version : str, optional
        Version of the FlyWire connectome dataset ('630' or '783'), defaults to '630'
    neural_activity_id : str, optional
        Identifier for neural activity dataset, defaults to '2017-10-26_1'
    neural_activity_max_fr : u.Quantity, optional
        Maximum firing rate for normalization, defaults to 100 Hz
    n_rank : int, optional
        Rank for low-rank approximation in LoRA, defaults to 20
    scale_factor : u.Quantity, optional
        Scaling factor for sparse connectivity weights, defaults to 0.3*0.275/7 mV
    conn_param_type : type, optional
        Parameter type for connection weights, defaults to brainscale.ETraceParam
    input_param_type : type, optional
        Parameter type for input weights, defaults to brainscale.ETraceParam
    sampling_rate : u.Quantity, optional
        Rate at which to sample neural activity, defaults to 1.2 Hz
    seed : int, optional
        Random seed for reproducibility, defaults to 2025
    bin_size : u.Quantity, optional
        Size of bins for firing rate discretization, defaults to 0.1 Hz
    noise_sigma : float, optional
        Standard deviation for noise injection during simulation, defaults to 0.1

    Attributes
    ----------
    pop : Population
        Neural population containing the simulated neurons
    neural_activity : NeuralActivity
        Module handling neural activity data and conversions
    interaction : Interaction
        Module implementing synaptic interactions between neurons
    n_sample_step : int
        Number of simulation steps per sample period
    flywire_version : str
        Version of the FlyWire connectome being used
    """

    def __init__(
        self,
        flywire_version: str = '630',
        neural_activity_id: str = '2017-10-26_1',
        neural_activity_max_fr: u.Quantity = 100. * u.Hz,
        n_rank: int = 20,
        scale_factor=0.3 * 0.275 / 7 * u.mV,
        conn_param_type: type = brainscale.ETraceParam,
        input_param_type: type = brainscale.ETraceParam,
        sampling_rate: u.Quantity = 1.2 * u.Hz,
        seed: int = 2025,
        bin_size: u.Quantity = 0.1 * u.Hz,
        noise_sigma: float = 0.1,
    ):
        super().__init__()

        # parameters
        self.flywire_version = flywire_version
        self.n_sample_step = int(1 / sampling_rate / brainstate.environ.get_dt())

        # population and its input
        self.pop = Population(
            flywire_version,
            V_init=v_init,
            g_init=g_init,
            tau_ref=5.0 * u.ms
        )

        # neural activity data
        self.neural_activity = NeuralActivity(
            pop=self.pop,
            flywire_version=flywire_version,
            neural_activity_id=neural_activity_id,
            neural_activity_max_fr=neural_activity_max_fr,
            param_type=input_param_type,
            seed=seed,
            bin_size=bin_size,
            noise_sigma=noise_sigma,
        )

        # network
        self.interaction = Interaction(
            self.pop,
            n_rank=n_rank,
            scale_factor=scale_factor,
            conn_param_type=conn_param_type,
        )

    def count_neuropil_fr(self, length: int = None):
        if length is None:
            length = self.n_sample_step
        neuron_fr = self.pop.spike_count.value / (length * brainstate.environ.get_dt())
        neuron_fr = neuron_fr.to(u.Hz)
        fun = self.neural_activity.neuron_to_neuropil_fr
        for i in range(neuron_fr.ndim - 1):
            fun = jax.vmap(fun)
        neuropil_fr = fun(neuron_fr)
        return neuropil_fr

    def update(self, i, embedding: u.Quantity):
        with brainstate.environ.context(i=i, t=i * brainstate.environ.get_dt()):
            # give inputs
            self.neural_activity.update(embedding)

            # update network
            spk = self.interaction.update()
            return spk

    def update_test(self, i, noise_weight):
        with brainstate.environ.context(i=i, t=i * brainstate.environ.get_dt()):
            # give inputs
            self.neural_activity.update_test(noise_weight)

            # update network
            spk = self.interaction.update()
            return spk

    @brainstate.compile.jit(static_argnums=0)
    def simulate(self, inp_embedding, indices):
        def step_run(i):
            self.update_test(i, noise_weight)

        noise_weight = self.neural_activity.neuropil2neuron(inp_embedding)
        self.pop.reset_spk_count()
        brainstate.compile.for_loop(step_run, indices)
        frs = self.count_neuropil_fr(indices.shape[0])
        return frs


class SpikingNetworkTrainer:
    """
    A class for training spiking neural network models to simulate firing rate patterns
    in Drosophila whole brain data.

    This trainer implements a two-stage training approach:
    1. First round: Trains a spiking neural network to match target neuropil firing rates
    2. Second round (separate method): Trains a recurrent neural network to decode firing patterns

    The class handles training of network parameters using gradient-based optimization with
    eligibility traces for biologically plausible learning.

    Parameters
    ----------
    sim_before_train : float, optional
        Proportion of steps to simulate before recording eligibility traces, defaults to 0.5
    lr : float, optional
        Learning rate for the optimizer, defaults to 1e-3
    etrace_decay : float or None, optional
        Decay factor for eligibility traces (None or 0 for standard backprop), defaults to 0.99
    grad_clip : float or None, optional
        Maximum norm for gradient clipping, defaults to 1.0
    neural_activity_id : str, optional
        Identifier for neural activity dataset, defaults to '2017-10-26_1'
    flywire_version : str, optional
        Version of the FlyWire connectome dataset ('630' or '783'), defaults to '630'
    max_firing_rate : u.Quantity, optional
        Maximum firing rate for normalization, defaults to 100 Hz
    loss_fn : str, optional
        Loss function ('mse', 'mae', 'huber', 'cosine_distance', 'log_cosh'), defaults to 'mse'
    vjp_method : str, optional
        Method for vector-Jacobian product calculation, defaults to 'single-step'
    n_rank : int, optional
        Rank for low-rank approximation in LoRA, defaults to 20
    conn_param_type : type, optional
        Parameter type for connection weights, defaults to brainscale.ETraceParam
    input_param_type : type, optional
        Parameter type for input weights, defaults to brainscale.ETraceParam
    scale_factor : u.Quantity, optional
        Scaling factor for sparse connectivity weights, defaults to 0.01 mV
    seed : int, optional
        Random seed for reproducibility, defaults to 2025
    noise_sigma : float, optional
        Standard deviation for noise injection during training, defaults to 0.1
    bin_size : u.Quantity, optional
        Size of bins for firing rate discretization, defaults to 0.1 Hz

    Methods
    -------
    get_loss(current_neuropil_fr, target_neuropil_fr)
        Computes loss between current and target neuropil firing rates
    train(input_embed, target_neuropil_fr)
        Performs one training step with given input and target
    show_res(neuropil_fr, target_neuropil_fr, i_epoch, i_batch, n_neuropil_per_fig=10)
        Visualizes results comparing simulated vs. target firing rates
    round1_train(train_epoch, batch_size=128, checkpoint_path=None)
        Executes the first round of training
    """

    def __init__(
        self,
        sim_before_train: float = 0.5,
        lr: float = 1e-3,
        etrace_decay: float | None = 0.99,
        grad_clip: float | None = 1.0,

        # network parameters
        neural_activity_id: str = '2017-10-26_1',
        flywire_version: str = '630',
        max_firing_rate: u.Quantity = 100. * u.Hz,
        loss_fn: str = 'mse',
        vjp_method: str = 'single-step',
        n_rank: int = 20,
        conn_param_type: type = brainscale.ETraceParam,
        input_param_type: type = brainscale.ETraceParam,
        scale_factor=0.01 * u.mV,
        seed: int = 2025,
        noise_sigma: float = 0.1,
        bin_size: u.Quantity = 0.1 * u.Hz,
    ):
        # parameters
        self.sim_before_train = sim_before_train
        self.etrace_decay = etrace_decay
        self.grad_clip = grad_clip
        self.loss_fn = loss_fn
        self.vjp_method = vjp_method

        # population and its input
        self.target = DrosophilaSpikingNetwork(
            flywire_version=flywire_version,
            neural_activity_id=neural_activity_id,
            neural_activity_max_fr=max_firing_rate,
            conn_param_type=conn_param_type,
            input_param_type=input_param_type,
            scale_factor=scale_factor,
            n_rank=n_rank,
            seed=seed,
            bin_size=bin_size,
            noise_sigma=noise_sigma,
        )

        # optimizer
        self.trainable_weights = brainstate.graph.states(self.target, brainstate.ParamState)
        self.opt = brainstate.optim.Adam(lr)
        self.opt.register_trainable_weights(self.trainable_weights)

        # train save path
        time_ = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
        self.filepath = (
            f'results/'
            f'v4_2/'
            f'{flywire_version}#'
            f'{neural_activity_id}#'
            f'{max_firing_rate / u.Hz}Hz#'
            f'{etrace_decay}#'
            f'{loss_fn}#'
            f'{conn_param_type.__name__}#'
            f'{input_param_type.__name__}#'
            f'{scale_factor.to_decimal(u.mV):5f}#'
            f'{n_rank}#'
            f'{sim_before_train}#'
            f'{seed}#'
            f'{bin_size.to_decimal(u.Hz)}#'
            f'{noise_sigma}#'
            f'{time_}'
        )

    def get_loss(self, current_neuropil_fr, target_neuropil_fr):
        if self.loss_fn == 'mse':
            loss = braintools.metric.squared_error(current_neuropil_fr, target_neuropil_fr)
        elif self.loss_fn == 'mae':
            loss = braintools.metric.absolute_error(current_neuropil_fr, target_neuropil_fr)
        elif self.loss_fn == 'huber':
            loss = braintools.metric.huber_loss(current_neuropil_fr, target_neuropil_fr)
        elif self.loss_fn == 'cosine_distance':
            loss = braintools.metric.cosine_distance(current_neuropil_fr, target_neuropil_fr)
        elif self.loss_fn == 'log_cosh':
            loss = braintools.metric.log_cosh(current_neuropil_fr, target_neuropil_fr)
        else:
            raise ValueError(f'Unknown loss function: {self.loss_fn}')
        return loss

    @brainstate.compile.jit(static_argnums=0)
    def train(self, input_embed, target_neuropil_fr):
        indices = np.arange(self.target.n_sample_step)

        # last_neuropil_fr: [n_batch, n_neuropil]
        # target_neuropil_fr: [n_batch, n_neuropil]
        n_batch = input_embed.shape[0]

        # model
        if self.etrace_decay is None or self.etrace_decay == 0.:
            model = brainscale.ParamDimVjpAlgorithm(self.target, vjp_method=self.vjp_method)
        else:
            model = brainscale.IODimVjpAlgorithm(self.target, self.etrace_decay, vjp_method=self.vjp_method)
        brainstate.nn.vmap_init_all_states(self.target, axis_size=n_batch, state_tag='hidden')

        @brainstate.augment.vmap_new_states(
            state_tag='etrace',
            axis_size=n_batch,
            in_states=self.target.states('hidden')
        )
        def init():
            model.compile_graph(0, input_embed[0])
            model.show_graph()

        init()

        # simulation without record eligibility trace
        n_sim = int(self.sim_before_train * self.target.n_sample_step)
        if n_sim > 0:
            batch_target = brainstate.nn.Vmap(self.target, vmap_states='hidden', in_axes=(None, 0))
            brainstate.compile.for_loop(
                lambda i: batch_target(i, input_embed),
                indices[:n_sim],
            )

        # simulation with eligibility trace recording
        self.target.pop.reset_spk_count(n_batch)
        model = brainstate.nn.Vmap(model, vmap_states=('hidden', 'etrace'), in_axes=(None, 0))
        brainstate.compile.for_loop(
            lambda i: model(i, input_embed),
            indices[n_sim:-1],
        )

        # training
        def loss_fn(i):
            spk = model(i, input_embed)
            current_neuropil_fr = self.target.count_neuropil_fr(self.target.n_sample_step - n_sim)
            loss_ = self.get_loss(current_neuropil_fr, target_neuropil_fr).mean()
            return u.get_mantissa(loss_), current_neuropil_fr

        grads, loss, neuropil_fr = brainstate.augment.grad(
            loss_fn, self.trainable_weights, return_value=True, has_aux=True
        )(indices[-1])
        max_g = jax.tree.map(lambda x: jnp.abs(x).max(), grads)
        if self.grad_clip is not None:
            grads = brainstate.functional.clip_grad_norm(grads, self.grad_clip)
        self.opt.update(grads)

        target_bin_indices = neuropil_to_bin_indices(target_neuropil_fr, self.target.neural_activity.bins)
        predict_bin_indices = neuropil_to_bin_indices(neuropil_fr, self.target.neural_activity.bins)
        acc = jnp.mean(jnp.asarray(target_bin_indices == predict_bin_indices, dtype=jnp.float32))

        return loss, neuropil_fr, max_g, acc

    def show_res(self, neuropil_fr, target_neuropil_fr, i_epoch, i_batch, n_neuropil_per_fig=10):
        fig, gs = braintools.visualize.get_figure(n_neuropil_per_fig, 2, 2., 10)
        for i in range(n_neuropil_per_fig):
            xticks = (i + 1 == n_neuropil_per_fig)
            fig.add_subplot(gs[i, 0])
            barplot(
                self.target.neural_activity.neuropils,
                neuropil_fr[i].to_decimal(u.Hz),
                title='Simulated FR',
                xticks=xticks
            )
            fig.add_subplot(gs[i, 1])
            barplot(
                self.target.neural_activity.neuropils,
                target_neuropil_fr[i].to_decimal(u.Hz),
                title='True FR',
                xticks=xticks
            )
        filename = f'{self.filepath}/images/neuropil_fr-at-epoch-{i_epoch}-batch-{i_batch}.png'
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        plt.savefig(filename)
        plt.close()

    def round1_train(
        self,
        train_epoch: int,
        batch_size: int = 128,
        checkpoint_path: str = None,
    ):
        if checkpoint_path is not None:
            braintools.file.msgpack_load(checkpoint_path, self.target.states(brainstate.ParamState))
            filepath = os.path.join(os.path.dirname(checkpoint_path), 'new')
            os.makedirs(filepath, exist_ok=True)
        else:
            filepath = self.filepath

        # training process
        os.makedirs(filepath, exist_ok=True)
        with open(f'{filepath}/losses.txt', 'w') as file:

            # training
            max_acc = 0.
            for i_epoch in range(train_epoch):
                i_batch = 0
                all_loss = []
                all_acc = []
                for input_embed, target_neuropil_fr in self.target.neural_activity.iter_data(
                    batch_size=batch_size, drop_last=True, test_phase=False
                ):
                    t0 = time.time()
                    res = self.train(input_embed, target_neuropil_fr)
                    loss, neuropil_fr, max_g, acc = jax.block_until_ready(res)
                    t1 = time.time()

                    output(
                        file,
                        f'epoch = {i_epoch}, '
                        f'batch = {i_batch}, '
                        f'loss = {loss:.5f}, '
                        f'bin acc = {acc:.5f}, '
                        f'lr = {self.opt.lr():.6f}, '
                        f'time = {t1 - t0:.5f}s'
                    )
                    output(file, f'max_g = {max_g}')

                    i_batch += 1
                    all_loss.append(loss)
                    all_acc.append(acc)
                self.show_res(neuropil_fr, target_neuropil_fr, i_epoch, '')
                self.opt.lr.step_epoch()

                # save checkpoint
                loss = np.mean(all_loss)
                acc = np.mean(all_acc)
                output(
                    file,
                    f'epoch = {i_epoch}, '
                    f'loss = {loss:.5f}, '
                    f'bin acc = {acc:.5f}, '
                    f'lr = {self.opt.lr():.6f}'
                )
                if acc > max_acc:
                    braintools.file.msgpack_save(
                        f'{filepath}/best-checkpoint.msgpack',
                        self.target.states(brainstate.ParamState),
                    )
                    max_acc = acc


def load_setting(filepath):
    """
    Parse settings from a filepath string containing model configuration parameters.

    This function extracts training and model configuration parameters from a structured
    filepath string where parameters are delimited by '#' characters. It parses parameters
    like FlyWire version, neural activity ID, maximum firing rate, and other hyperparameters
    used for model training.

    Parameters
    ----------
    filepath : str
        A filepath string containing configuration parameters delimited by '#'.
        Expected format: 'path/to/dir/flywire_version#neural_activity_id#max_fr#etrace_decay#loss_fn#...'

    Returns
    -------
    dict
        A dictionary containing all parsed settings with their appropriate types.
        Keys include: flywire_version, neural_activity_id, max_firing_rate, etrace_decay,
        loss_fn, conn_param_type, input_param_type, scale_factor, n_rank, sim_before_train,
        seed, bin_size, noise_sigma, and filepath itself.

    Notes
    -----
    The function handles type conversion for numeric parameters and ensures
    quantities have appropriate units attached (e.g., Hz for firing rates).
    """
    setting = filepath.split('/')[2].split('#')
    flywire_version = setting[0]
    neural_activity_id = setting[1]
    max_firing_rate = float(setting[2].split('Hz')[0]) * u.Hz
    etrace_decay = eval(setting[3])
    loss_fn = setting[4]
    conn_param_type = setting[5]
    input_param_type = setting[6]
    scale_factor = float(setting[7]) * u.mV
    n_rank = int(setting[8])
    sim_before_train = float(setting[9])
    seed = int(setting[10])
    bin_size = float(setting[11]) * u.Hz
    noise_sigma = float(setting[12])
    return locals()


def first_round_train():
    """
    Train the first round of a spiking neural network to simulate Drosophila brain activity.

    This function configures and executes the first round of training for the spiking neural network,
    which aims to reproduce neuropil firing rates observed in the Drosophila brain. It either
    initializes a new training session or continues from a checkpoint with appropriate settings.

    The function handles:
    - Setting training parameters (epochs, learning rate, etc.)
    - Loading checkpoint settings if provided
    - Configuring environment settings such as time step
    - Initializing and running the SpikingNetworkTrainer

    The training process maps neural activity from previous time steps to predict activity
    at the current time step using a biologically plausible spiking neural network with
    eligibility trace-based learning.

    Notes
    -----
    - Default parameters are set for a new training session if no checkpoint is provided
    - When resuming from a checkpoint, parameters are extracted from the checkpoint filepath
    - Uses a 0.2 ms simulation time step
    """
    checkpoint_path = None

    train_epoch = 500
    if checkpoint_path is None:
        neural_activity_id = '2017-10-26_1'
        flywire_version = '630'
        lr, etrace_decay, scale_factor, bin_size, noise_sigma = 1e-2, 0.99, 0.0825 / 100 * u.mV, 0.25 * u.Hz, 0.05
    else:
        lr = brainstate.optim.StepLR(1e-3, step_size=50, gamma=0.9)
        settings = checkpoint_path.split('/')[2].split('#')
        flywire_version = settings[0]
        neural_activity_id = settings[1]
        etrace_decay = float(settings[3])
        conn_param_type = settings[5]
        input_param_type = settings[6]
        scale_factor = float(settings[7]) * u.mV
        n_rank = int(settings[8])
        sim_before_train = float(settings[9])
        bin_size = float(settings[11]) * u.Hz
        noise_sigma = float(settings[12])

    brainstate.environ.set(dt=0.2 * u.ms)
    trainer = SpikingNetworkTrainer(
        lr=lr,
        etrace_decay=etrace_decay,
        sim_before_train=0.1,
        neural_activity_id=neural_activity_id,
        flywire_version=flywire_version,
        max_firing_rate=100.0 * u.Hz,
        loss_fn='mse',
        scale_factor=scale_factor,
        conn_param_type=brainscale.ETraceParam if etrace_decay != 0. else brainscale.NonTempParam,
        input_param_type=brainscale.ETraceParam if etrace_decay != 0. else brainscale.NonTempParam,
        bin_size=bin_size,
        noise_sigma=noise_sigma,
    )
    trainer.round1_train(
        train_epoch=train_epoch,
        batch_size=128,
        checkpoint_path=checkpoint_path
    )


def first_round_generate_training_data():
    """
    Generate simulated neural activity training data using a pre-trained spiking neural network.

    This function loads parameters from a trained model checkpoint, initializes a FiringRateNetwork
    with those parameters, and simulates neural activity across the full time series of the
    original dataset. For each time step, it captures the simulated neuropil firing rates
    and calculates similarity metrics between simulated and target data.

    The generated data is saved in the same directory as the checkpoint file and can be used
    for subsequent training of recurrent neural networks or other downstream models.

    Notes
    -----
    - Uses a hard-coded filepath to load a specific model checkpoint
    - Initializes network states and parameters from the checkpoint
    - Simulates activity time step by time step, recording firing rates
    - Calculates similarity metrics between simulated and target firing rates
    - Progress is displayed using a tqdm progress bar
    """
    brainstate.environ.set(dt=0.2 * u.ms)

    filepath = 'results/v4_2/630#2017-10-26_1#100.0Hz#0.99#mse#ETraceParam#ETraceParam#0.000825#20#0.1#2025#0.25#0.05#2025-04-12-20-55-49/best-checkpoint.msgpack'
    setting = filepath.split('/')[2].split('#')
    flywire_version = setting[0]
    neural_activity_id = setting[1]
    max_firing_rate = float(setting[2].split('Hz')[0]) * u.Hz
    etrace_decay = eval(setting[3])
    loss_fn = setting[4]
    conn_param_type = setting[5]
    input_param_type = setting[6]
    scale_factor = float(setting[7]) * u.mV
    n_rank = int(setting[8])
    sim_before_train = float(setting[9])
    seed = int(setting[10])
    bin_size = float(setting[11]) * u.Hz
    noise_sigma = float(setting[12])

    net = DrosophilaSpikingNetwork(
        flywire_version=flywire_version,
        neural_activity_id=neural_activity_id,
        neural_activity_max_fr=max_firing_rate,
        conn_param_type=getattr(brainscale, conn_param_type),
        input_param_type=getattr(brainscale, input_param_type),
        n_rank=n_rank,
        scale_factor=scale_factor,
        seed=seed,
        bin_size=bin_size,
        noise_sigma=noise_sigma,
    )
    braintools.file.msgpack_load(filepath, net.states(brainstate.ParamState))
    brainstate.nn.init_all_states(net)

    @brainstate.compile.jit
    def one_step(i, indices):
        input_embed = net.neural_activity.spike_rates[i] / u.Hz
        output_neuropil_fr = net.neural_activity.spike_rates[i + 1]
        net.simulate(input_embed, indices[:n_sim])
        neuropil_fr = net.simulate(input_embed, indices[n_sim:]).to_decimal(u.Hz)
        sim = jnp.corrcoef(u.get_mantissa(output_neuropil_fr), neuropil_fr)[0, 1]
        return neuropil_fr, sim

    n_sim = int(sim_before_train * net.n_sample_step)
    simulated_neuropil_fr = []
    indices = np.arange(net.n_sample_step)
    bar = tqdm(total=net.neural_activity.n_time)
    all_sim = []
    for i in range(0, net.neural_activity.n_time):
        neuropil_fr, sim = one_step(i, indices)
        bar.update()
        bar.set_description(f'similarity = {sim:.5f}')
        indices = indices + net.n_sample_step
        simulated_neuropil_fr.append(neuropil_fr)
        all_sim.append(sim)
    bar.close()
    print(f'Mean similarity = {np.mean(np.mean(all_sim)):.5f}')
    simulated_neuropil_fr = np.asarray(simulated_neuropil_fr)  # [n_time, n_neuropil]
    np.save(os.path.join(os.path.dirname(filepath), 'simulated_neuropil_fr'), simulated_neuropil_fr)


class DrosophilaInputEncoder(brainstate.nn.Module):
    """
    Neural network encoder for processing and transforming Drosophila neural activity data.

    This module implements a recurrent neural network architecture for encoding
    time-series neural activity data in the Drosophila brain. It processes input firing
    rates through normalization, a GRU cell for temporal context, and a linear readout
    layer to produce output firing rates.

    The encoder is designed to be used in the second round of training after the spiking
    neural network has been trained, serving as a decoder/predictor of neural activity
    patterns.

    Parameters
    ----------
    n_in : int
        Number of input features (typically number of neuropils in the dataset)
    n_hidden : int
        Size of the hidden state in the GRU cell
    n_out : int
        Number of output features (typically matches n_in for autoencoding)

    Attributes
    ----------
    norm : brainstate.nn.LayerNorm
        Layer normalization module for input standardization
    rnn : brainstate.nn.GRUCell
        Gated Recurrent Unit cell for processing sequential data
    readout : brainstate.nn.Linear
        Linear transformation from hidden state to output firing rates
    """

    def __init__(self, n_in, n_hidden, n_out):
        super().__init__()
        self.norm = brainstate.nn.LayerNorm(n_in, use_scale=False, use_bias=False)
        self.rnn = brainstate.nn.GRUCell(n_in, n_hidden)
        self.readout = brainstate.nn.Linear(n_hidden, n_out)

    def update(self, x):
        norm = self.norm(u.get_mantissa(x))
        rnn = self.rnn(norm)
        readout = self.readout(rnn)
        return brainstate.functional.relu(readout) * u.Hz


def second_round_train():
    """
    Train the second round of neural network to predict firing rates based on simulated data.

    This function loads simulated neural activity data generated from a previously trained
    spiking neural network and trains a recurrent neural network (DrosophilaInputEncoder)
    to predict firing rates in the Drosophila brain. The second round of training focuses
    on creating a more efficient model that can generalize from the simulated data.

    The function handles:
    - Loading parameters and simulation results from the first round
    - Setting up the recurrent neural network architecture
    - Generating training inputs with appropriate noise augmentation
    - Training the model with gradient-based optimization
    - Monitoring performance metrics (loss and bin accuracy)
    - Saving the best model checkpoint based on loss

    Notes
    -----
    - Uses a GRU-based encoder architecture (DrosophilaInputEncoder)
    - Applies noise to input data for robustness
    - Monitors bin accuracy (correctly classified firing rate bins)
    - Uses a step learning rate schedule that decays over time
    - Saves the best model checkpoint based on loss value
    """
    filepath = 'results/v4_2/630#2017-10-26_1#100.0Hz#0.99#mse#ETraceParam#ETraceParam#0.000825#20#0.1#2025#0.25#0.05#2025-04-12-20-55-49'
    setting = filepath.split('/')[2].split('#')
    flywire_version = setting[0]
    neural_activity_id = setting[1]
    max_firing_rate = float(setting[2].split('Hz')[0]) * u.Hz
    etrace_decay = eval(setting[3])
    # loss_fn = setting[4]
    conn_param_type = setting[5]
    input_param_type = setting[6]
    scale_factor = float(setting[7]) * u.mV
    n_rank = int(setting[8])
    sim_before_train = float(setting[9])
    seed = int(setting[10])
    bin_size = float(setting[11]) * u.Hz
    noise_sigma = float(setting[12])
    noise_sigma = 0.1

    n_hidden = 256
    batch_size = 128
    input_style = 'v1'
    lr = brainstate.optim.StepLR(5e-3, step_size=10, gamma=0.9)
    lr = brainstate.optim.StepLR(1e-3, step_size=10, gamma=0.9)

    data = np.load(f'data/spike_rates/ito_{neural_activity_id}_spike_rate.npz')
    spike_rates = u.math.asarray(data['rates'][1:] * max_firing_rate).T
    targets = spike_rates[1:]
    bins = get_bins(spike_rates, bin_size, max_firing_rate)
    true_bin_indices = neuropil_to_bin_indices(targets, bins)
    simulated_spike_rates = np.load(os.path.join(filepath, 'simulated_neuropil_fr.npy'))
    # scales = jnp.minimum(simulated_spike_rates * noise_sigma, 0.1)
    scales = 0.1
    # true_scales = spike_rates / u.Hz * noise_sigma
    # true_scales = 0.05

    bin_indices = neuropil_to_bin_indices(spike_rates, bins)
    low_rates = bins[bin_indices - 1]
    high_rates = bins[bin_indices]

    @brainstate.compile.jit
    def generate_inputs():
        simulation_sample_fn = jax.vmap(lambda key: brainstate.random.normal(simulated_spike_rates, scales, key=key))
        simulation_sample_fn = jax.vmap(
            lambda key: jax.random.normal(key, simulated_spike_rates.shape) * scales + simulated_spike_rates)

        if input_style == 'v1':
            # sampled_spike_rates = brainstate.random.normal(spike_rates / u.Hz, true_scales)
            # sampled_spike_rates = jnp.minimum(sampled_spike_rates, 0.)
            # bin_indices = jax.vmap(neuropil_to_bin_indices, in_axes=(0, None))(sampled_spike_rates * u.Hz, bins)
            # low_rates = bins[bin_indices - 1]
            # high_rates = bins[bin_indices]
            true_sample_fn = jax.vmap(lambda key: brainstate.random.uniform(low_rates, high_rates, key=key))
            true_sampling = true_sample_fn(brainstate.random.split_key(batch_size // 2))

            simulation_sampling = simulation_sample_fn(brainstate.random.split_key(batch_size // 2))
            simulation_sampling = jnp.minimum(simulation_sampling, 0.)

            inputs = jnp.concatenate([true_sampling, simulation_sampling], axis=0)
            return jnp.transpose(inputs, (1, 0, 2))

        elif input_style == 'v2':
            simulation_sampling = simulation_sample_fn(brainstate.random.split_key(batch_size))
            simulation_sampling = jnp.minimum(simulation_sampling, 0.)
            return jnp.transpose(simulation_sampling, (1, 0, 2))

        else:
            raise ValueError(f'Unknown input style: {input_style}')

    net = DrosophilaInputEncoder(n_in=spike_rates.shape[1], n_hidden=n_hidden, n_out=spike_rates.shape[1])
    weights = net.states(brainstate.ParamState)
    opt = brainstate.optim.Adam(lr=lr)
    opt.register_trainable_weights(weights)

    # braintools.file.msgpack_load(os.path.join(filepath, f'second-round-rnn-checkpoint-{input_style}.msgpack'), weights)

    def f_predict(inputs):
        # inputs = norm(inputs)
        brainstate.nn.vmap_init_all_states(net, axis_size=batch_size)
        return brainstate.compile.for_loop(net, inputs)

    def verify_acc(predictions):
        pred_bin_indices = neuropil_to_bin_indices(predictions, bins)
        acc = jnp.asarray(pred_bin_indices == true_bin_indices, dtype=float).mean()
        return acc

    def loss_fn(predictions):
        mse = (
            u.math.square(u.math.relu(low_rates[1:] - predictions / u.Hz)) +
            u.math.square(u.math.relu(predictions / u.Hz - high_rates[1:]))
        ).mean()
        return mse

    def f_loss(inputs):
        predictions = f_predict(inputs)
        predictions = u.math.transpose(predictions[:-1], (1, 0, 2))
        mse = loss_fn(predictions)
        acc = jax.vmap(verify_acc)(predictions).mean()
        return mse, acc

    @brainstate.compile.jit
    def f_train(inputs):
        grads, l, acc = brainstate.augment.grad(f_loss, weights, return_value=True, has_aux=True)(inputs)
        opt.update(grads)
        return l, acc

    @brainstate.compile.jit
    def f_test():
        brainstate.nn.init_all_states(net)
        outputs = brainstate.compile.for_loop(net, simulated_spike_rates)
        mse = loss_fn(outputs[:-1])
        acc = jax.vmap(verify_acc)(outputs[:-1]).mean()
        return mse, acc

    all_loss = []
    all_acc = []
    min_loss = np.inf
    t0 = time.time()
    for i_epoch in range(1000):
        train_loss_epoch = []
        train_acc_epoch = []
        for i_batch in range(100):
            inputs = generate_inputs()
            loss, acc = f_train(inputs)
            train_acc_epoch.append(acc)
            train_loss_epoch.append(loss)
        acc = np.mean(train_acc_epoch)
        loss = np.mean(train_loss_epoch)
        test_mse, test_acc = f_test()
        print(
            f'Epoch = {i_epoch}, '
            f'Train Loss = {loss:.5f}, '
            f'Train bin acc = {acc:.5f}, '
            f'Test Loss = {test_mse:.5f}, '
            f'Test bin acc = {test_acc:.5f}, '
            f'lr = {opt.lr():.6f}, '
            f'time = {time.time() - t0:.2f} s'
        )
        opt.lr.step_epoch()
        if min_loss > test_mse:
            min_loss = test_mse
            braintools.file.msgpack_save(f'{filepath}/second-round-rnn-checkpoint-{input_style}.msgpack',
                                         net.states(brainstate.LongTermState))
        t0 = time.time()

    fig, gs = braintools.visualize.get_figure(1, 2, 3, 4)
    fig.add_subplot(gs[0, 0])
    plt.plot(all_loss)
    plt.xlabel('Batch')
    plt.ylabel('Loss')
    fig.add_subplot(gs[0, 1])
    plt.plot(all_acc)
    plt.xlabel('Batch')
    plt.ylabel('Bin accuracy')
    plt.show()


def second_round_loading():
    filepath = 'results/v4_2/630#2017-10-26_1#100.0Hz#0.99#mse#ETraceParam#ETraceParam#0.000825#20#0.1#2025#0.25#0.05#2025-04-12-20-55-49'
    setting = filepath.split('/')[2].split('#')
    flywire_version = setting[0]
    neural_activity_id = setting[1]
    max_firing_rate = float(setting[2].split('Hz')[0]) * u.Hz
    etrace_decay = eval(setting[3])
    # loss_fn = setting[4]
    conn_param_type = setting[5]
    input_param_type = setting[6]
    scale_factor = float(setting[7]) * u.mV
    n_rank = int(setting[8])
    sim_before_train = float(setting[9])
    seed = int(setting[10])
    bin_size = float(setting[11]) * u.Hz
    noise_sigma = float(setting[12])
    noise_sigma = 0.1

    data = np.load(f'data/spike_rates/ito_{neural_activity_id}_spike_rate.npz')
    spike_rates = u.math.asarray(data['rates'][1:] * max_firing_rate).T
    simulated_spike_rates = np.load(os.path.join(filepath, 'simulated_neuropil_fr.npy'))
    n_hidden = 256

    net = DrosophilaInputEncoder(n_in=spike_rates.shape[1], n_hidden=n_hidden, n_out=spike_rates.shape[1])
    norm = brainstate.nn.LayerNorm(spike_rates.shape[1])
    braintools.file.msgpack_load(os.path.join(filepath, f'second-round-rnn-checkpoint-v1.msgpack'),
                                 net.states(brainstate.LongTermState))

    brainstate.nn.init_all_states(net)
    outputs = brainstate.compile.for_loop(lambda x: net(norm(x)), simulated_spike_rates)

    times = np.arange(simulated_spike_rates.shape[0]) * 0.8 * u.second
    num = 5
    for ii in range(0, spike_rates.shape[1], num):
        fig, gs = braintools.visualize.get_figure(num, 2, 4, 8.0)
        for i in range(num):
            # plot simulated neuropil firing rate data
            fig.add_subplot(gs[i, 0])
            data = outputs[:, i + ii]
            plt.plot(times, data)
            plt.ylim(0., data.max() * 1.05)
            # plot experimental neuropil firing rate data
            fig.add_subplot(gs[i, 1])
            data = simulated_spike_rates[:, i + ii]
            plt.plot(times, data)
            plt.ylim(0., data.max() * 1.05)
        plt.show()


def example_to_simulate():
    import matplotlib.pyplot as plt
    brainstate.environ.set(dt=0.2 * u.ms)
    net = DrosophilaSpikingNetwork(
        flywire_version='630',
        neural_activity_id='2017-10-26_1',
        neural_activity_max_fr=100 * u.Hz,
        conn_param_type=brainscale.NonTempParam,
        input_param_type=brainscale.NonTempParam,
        n_rank=20,
        # scale_factor=0.0825 / 40 * u.mV,
        scale_factor=0.0825 / 100 * u.mV,
    )
    brainstate.nn.init_all_states(net)

    neuropil_fr = net.neural_activity.read_neuropil_fr(0)
    t0 = 0.0 * u.ms
    t1 = net.n_sample_step * brainstate.environ.get_dt()

    for i in range(10):
        neuropil_fr = net.simulate(neuropil_fr, t0, t0 + t1)
        fig, gs = braintools.visualize.get_figure(2, 1, 3, 10.0)
        fig.add_subplot(gs[0, 0])
        barplot(net.neural_activity.neuropils, neuropil_fr.to_decimal(u.Hz), title='Simulated FR')
        fig.add_subplot(gs[1, 0])
        target_neuropil_fr = net.neural_activity.read_neuropil_fr(i + 1)
        barplot(net.neural_activity.neuropils, target_neuropil_fr.to_decimal(u.Hz), title='True FR')
        plt.show()
        t0 += t1


def example_to_load():
    """
    Load and initialize a pre-trained Drosophila spiking neural network model for demonstration.

    This function demonstrates how to load a previously trained spiking neural network model
    from a checkpoint file and initialize it for use. It extracts configuration parameters
    from the checkpoint filepath, sets up the environment parameters, and initializes the
    DrosophilaSpikingNetwork with the extracted settings.

    The function is intended as an example showing how to:
    - Extract model hyperparameters from a checkpoint filepath
    - Configure the simulation environment
    - Initialize a spiking neural network with the appropriate parameters
    - Load trained weights from a checkpoint file

    Notes
    -----
    - Sets the simulation time step to 0.2 milliseconds
    - Uses a hardcoded filepath to a specific model checkpoint
    - Extracts all training parameters from the checkpoint filepath
    - Initializes but does not execute simulation (incomplete function)
    """
    brainstate.environ.set(dt=0.2 * u.ms)

    # filepath = 'results/v4_2/630#2017-10-26_1#100.0Hz#0.99#mse#ETraceParam#ETraceParam#0.000825#20#0.1#2025#0.5#0.1#2025-04-12-20-54-35'
    filepath = 'results/v4_2/630#2017-10-26_1#100.0Hz#0.99#mse#ETraceParam#ETraceParam#0.000825#20#0.1#2025#0.25#0.05#2025-04-12-20-55-49'
    setting = filepath.split('/')[2].split('#')
    flywire_version = setting[0]
    neural_activity_id = setting[1]
    max_firing_rate = float(setting[2].split('Hz')[0]) * u.Hz
    etrace_decay = eval(setting[3])
    loss_fn = setting[4]
    conn_param_type = setting[5]
    input_param_type = setting[6]
    scale_factor = float(setting[7]) * u.mV
    n_rank = int(setting[8])
    sim_before_train = float(setting[9])
    seed = int(setting[10])
    bin_size = float(setting[11]) * u.Hz
    noise_sigma = float(setting[12])

    # spiking neural network for spike generation
    spiking_net = DrosophilaSpikingNetwork(
        flywire_version=flywire_version,
        neural_activity_id=neural_activity_id,
        neural_activity_max_fr=max_firing_rate,
        conn_param_type=getattr(brainscale, conn_param_type),
        input_param_type=getattr(brainscale, input_param_type),
        n_rank=n_rank,
        scale_factor=scale_factor,
        seed=seed,
        bin_size=bin_size,
        noise_sigma=noise_sigma,
    )
    braintools.file.msgpack_load(os.path.join(filepath, 'best-checkpoint.msgpack'),
                                 spiking_net.states(brainstate.ParamState))
    brainstate.nn.init_all_states(spiking_net)

    # Recurrent neural network for decoding
    rnn_net = DrosophilaInputEncoder(
        n_in=spiking_net.neural_activity.n_neuropil,
        n_hidden=256,
        n_out=spiking_net.neural_activity.n_neuropil
    )
    braintools.file.msgpack_load(os.path.join(filepath, f'second-round-rnn-checkpoint-v1.msgpack'),
                                 rnn_net.states(brainstate.LongTermState))
    brainstate.nn.init_all_states(rnn_net)

    @brainstate.compile.jit
    def process(neuropil_firing_rate, indices):
        rnn_out = rnn_net(neuropil_firing_rate)
        spiking_net.simulate(rnn_out / u.Hz, indices[:n_sim])
        neuropil_fr = spiking_net.simulate(rnn_out / u.Hz, indices[n_sim:])
        target_neuropil_fr = spiking_net.neural_activity.read_neuropil_fr(i + 1)
        target_bin_indices = neuropil_to_bin_indices(target_neuropil_fr, spiking_net.neural_activity.bins)
        predict_bin_indices = neuropil_to_bin_indices(neuropil_fr, spiking_net.neural_activity.bins)
        acc = jnp.mean(jnp.asarray(target_bin_indices == predict_bin_indices, dtype=jnp.float32))
        mse = u.get_mantissa(u.math.square(target_neuropil_fr - neuropil_fr)).mean()
        return neuropil_fr, mse, acc

    # n_time = 200
    n_time = spiking_net.neural_activity.n_time
    n_sim = int(sim_before_train * spiking_net.n_sample_step)
    t1 = spiking_net.n_sample_step * brainstate.environ.get_dt()
    indices = np.arange(spiking_net.n_sample_step)
    bar = tqdm(total=n_time)
    all_accs = []
    all_losses = []
    simulated_neuropil_fr = []
    for i in range(n_time):
        # brainstate.nn.reset_all_states(net)
        if i < 100:
            neuropil_fr = spiking_net.neural_activity.read_neuropil_fr(i)
        neuropil_fr, mse, acc = process(neuropil_fr, indices)
        simulated_neuropil_fr.append(neuropil_fr.to_decimal(u.Hz))
        bar.set_description(f'Bin acc = {acc}, mse = {mse}')
        bar.update(1)
        all_losses.append(float(mse))
        all_accs.append(float(acc))
        indices += spiking_net.n_sample_step
    simulated_neuropil_fr = np.asarray(simulated_neuropil_fr)  # [n_time, n_neuropil]
    print(
        f'Mean bin acc  = {np.mean(all_accs):.5f}, '
        f'mean mse loss = {np.mean(all_losses):.5f}'
    )
    np.save(os.path.join(filepath, 'neuropil_fr_predictions'), simulated_neuropil_fr)

    experimental_neuropil_fr = np.asarray(spiking_net.neural_activity.spike_rates / u.Hz)  # [n_time, n_neuropil]
    times = np.arange(simulated_neuropil_fr.shape[0]) * t1
    num = 5
    for ii in range(0, spiking_net.neural_activity.n_neuropil, num):
        fig, gs = braintools.visualize.get_figure(num, 2, 4, 8.0)
        for i in range(num):
            # plot simulated neuropil firing rate data
            fig.add_subplot(gs[i, 0])
            data = simulated_neuropil_fr[:, i + ii]
            plt.plot(times, data)
            plt.ylim(0., data.max() * 1.05)
            # plot experimental neuropil firing rate data
            fig.add_subplot(gs[i, 1])
            data = experimental_neuropil_fr[:n_time, i + ii]
            plt.plot(times, data)
            plt.ylim(0., data.max() * 1.05)
        plt.show()


if __name__ == '__main__':
    pass
    # first_round_train()
    # generate_training_data()
    # second_round_train()
    # second_round_loading()
    example_to_load()
    # example_to_simulate()
